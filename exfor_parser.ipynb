{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-23T15:52:57.594859Z",
     "start_time": "2025-10-23T15:52:56.064612Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re, os"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T15:52:57.612930Z",
     "start_time": "2025-10-23T15:52:57.599480Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_most_recent_data(target, reaction, exfor_dir):\n",
    "    most_recent = []\n",
    "    # Walk through directory, ignore subdirectories. Pick out each file\n",
    "    for folder, _, files in os.walk(exfor_dir):\n",
    "        for file_name in files:\n",
    "\n",
    "            # Build in some resilience\n",
    "            path = os.path.join(folder, file_name)\n",
    "            try:\n",
    "                # Open each file in turn and read it in\n",
    "                with open(path, encoding=\"utf-8\", errors=\"ignore\") as working_file:\n",
    "                    file_contents = working_file.read()\n",
    "\n",
    "                    # Check for the specific reaction, pick out date with regex\n",
    "                    if rf\"REACTION   ({target}{reaction}\" in file_contents:\n",
    "                        entry_line = re.search(r\"ENTRY\\s+\\S+\\s+(\\d{8})\", file_contents)\n",
    "\n",
    "                        #If the date exists, append the list\n",
    "                        if entry_line:\n",
    "                            most_recent.append((entry_line.group(1), path))\n",
    "\n",
    "            except Exception as exception_text:\n",
    "                # If it all goes wrong, where did it all go wrong?\n",
    "                print(f\"Skipped {path}: {exception_text}\")\n",
    "\n",
    "    # Tell me pls\n",
    "    most_recent.sort(reverse=True)\n",
    "    return most_recent"
   ],
   "id": "ac504681e770fd16",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T15:53:03.992026Z",
     "start_time": "2025-10-23T15:53:03.967319Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def parse_exfor_file(file_name):\n",
    "    #Create list of formatted sub-entries\n",
    "    sub_entries_formatted = []\n",
    "\n",
    "    # Open EXFOR file\n",
    "    with open(file_name, encoding=\"utf-8\", errors=\"ignore\") as working_file:\n",
    "        file_contents = working_file.read()\n",
    "\n",
    "    # Pick up and assign metadata\n",
    "    entry_match = re.search(r\"ENTRY\\s+(\\S+)\\s+(\\d{8})\", file_contents)\n",
    "    if entry_match:\n",
    "        entry_id = entry_match.group(1)\n",
    "        entry_date = entry_match.group(2)\n",
    "    else:\n",
    "        entry_id = None\n",
    "        entry_date = None\n",
    "\n",
    "    # Check to see if the file has subentries\n",
    "    if \"SUBENT\" in file_contents:\n",
    "        file_has_sub_entries = True\n",
    "    else:\n",
    "        file_has_sub_entries = False\n",
    "\n",
    "    # If the file has subentries, split it up into blocks. If not, make it one block\n",
    "    if file_has_sub_entries:\n",
    "        sub_entries = re.findall(r\"(SUBENT\\s+\\S+.*?ENDSUBENT)\", file_contents, re.S)\n",
    "    else:\n",
    "        sub_entries = [file_contents]\n",
    "\n",
    "    for sub_entry in sub_entries:\n",
    "        # Create list of dataframes\n",
    "        dataframes = []\n",
    "\n",
    "        # Pick up and assign metadata\n",
    "        sub_match = re.search(r\"SUBENT\\s+(\\S+)\\s+(\\d{8})\", sub_entry)\n",
    "        if sub_match:\n",
    "            sub_id = sub_match.group(1)\n",
    "            sub_date = sub_match.group(2)\n",
    "        else:\n",
    "            sub_id = None\n",
    "            sub_date = None\n",
    "\n",
    "        # Split up data block\n",
    "        data_blocks = re.findall(r\"DATA(.*?)ENDDATA\", sub_entry, re.S)\n",
    "        if not data_blocks and not file_has_sub_entries:\n",
    "            # Some single-entry files don't have data tags\n",
    "            data_blocks = [sub_entry]\n",
    "\n",
    "        # Create a Pandas dataframe to store the data\n",
    "        for block in data_blocks:\n",
    "            dataframe = create_dataframe(block)\n",
    "            if not dataframe.empty:\n",
    "                dataframes.append(dataframe)\n",
    "\n",
    "        # Add each sub-entry into the list\n",
    "        sub_entries_formatted.append({\n",
    "            \"subentry_id\": sub_id,\n",
    "            \"subentry_date\": sub_date,\n",
    "            \"data\": dataframes\n",
    "        })\n",
    "\n",
    "    # Return formatted database\n",
    "    return {\n",
    "        \"entry_id\": entry_id,\n",
    "        \"entry_date\": entry_date,\n",
    "        \"subentries\": sub_entries_formatted\n",
    "    }\n",
    "\n",
    "\n",
    "# Helper function to detect the units the block is in\n",
    "def read_in_headers_and_units(lines):\n",
    "    #Check to see if there is a \"DATA\" line. Sometimes it's on the same line, etc. (Poor formatting IMO)\n",
    "    data_index = next((i for i, l in enumerate(lines) if l.strip().upper().startswith(\"DATA\")), None)\n",
    "\n",
    "    # choose search segment\n",
    "    if data_index is not None:\n",
    "        search_start = data_index + 1\n",
    "    else:\n",
    "        search_start = 0\n",
    "\n",
    "    # lines to search\n",
    "    for index in range(search_start, len(lines)):\n",
    "        line = lines[index].strip()\n",
    "\n",
    "        # match header patterns common in EXFOR\n",
    "        if re.match(r\"^(EN-|EN\\s|EN-MIN\\b|EN-MAX\\b|EN-RES\\b|EN-EXP\\b|ENERGY\\b)\", line, re.IGNORECASE):\n",
    "\n",
    "            # Split header into a list\n",
    "            header = re.split(r\"\\s+\", line)\n",
    "\n",
    "            # Units should be here\n",
    "            units_idx = index + 1\n",
    "            units = None\n",
    "\n",
    "            # Clean things up\n",
    "            if units_idx < len(lines):\n",
    "                units_line = lines[units_idx].strip()\n",
    "\n",
    "                # only accept line if it has the right characters (This has to be here otherwise it throws a tantrum, for some reason)\n",
    "                if units_line and re.search(r\"[A-Za-z/*]\", units_line):\n",
    "                    units = re.split(r\"\\s+\", units_line)\n",
    "                else:\n",
    "                    units = None\n",
    "\n",
    "            # Start looking at data on the next line; even if no unit line\n",
    "            if units is not None:\n",
    "                start_idx = units_idx + 1\n",
    "            else:\n",
    "                start_idx = index + 1\n",
    "            return header, units, start_idx\n",
    "\n",
    "    # Fallback to nil vals\n",
    "    return None, None, 0\n",
    "\n",
    "\n",
    "# Helper to do the actual data parsing\n",
    "def parse_numeric_block(lines, start_index):\n",
    "    rows = []\n",
    "\n",
    "    # Check every line, starting after the units line\n",
    "    for line in lines[start_index:]:\n",
    "        # Break loop after data\n",
    "        if line.startswith(\"ENDDATA\"):\n",
    "            break\n",
    "\n",
    "        # Just in case the line doesn't have numbers in it for some reason (#EXFORsucks)\n",
    "        try:\n",
    "            numbers = []\n",
    "            for number in re.split(r\"\\s+\", line):\n",
    "                numbers.append(float(number))\n",
    "            rows.append(numbers)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "    # Return the dataframe with the numbers (hopefully) correctly formatted\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "\n",
    "# Helper to convert energy column to MeV\n",
    "def convert_energy_to_mev(dataframe, unit):\n",
    "    # Identify unit, set scale factors\n",
    "    unit = (unit or \"MEV\").upper()\n",
    "    factors = {\"EV\": 1e-6, \"KEV\": 1e-3, \"MEV\": 1.0, \"GEV\": 1e3}\n",
    "    factor = factors.get(unit, 1.0)\n",
    "\n",
    "    # Scale energy data, rename column appropriately\n",
    "    dataframe.iloc[:, 0] *= factor\n",
    "    dataframe.rename(columns={dataframe.columns[0]: \"Energy (MeV)\"}, inplace=True)\n",
    "\n",
    "    # This defaults to MeV in case of no units, which is maybe not ideal. Something to think about in the future, can't think of a solution rn.\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "# Helper to convert all reaction data to barns\n",
    "def convert_reaction_data(dataframe, units):\n",
    "    # Set scale factors\n",
    "    factors = {\n",
    "        \"B\": 1.0, \"MB\": 1e-3, \"UB\": 1e-6, \"NB\": 1e-9,\n",
    "        \"PB\": 1e-12, \"KB\": 1e3, \"MB*EV\": 1e-3, \"MB/SR\": 1e-3,\n",
    "        \"EV\": 1e-6, \"KEV\": 1e-3, \"MEV\": 1.0, \"GEV\": 1e3\n",
    "    }\n",
    "\n",
    "    # Iterate over the columns, scale each in turn\n",
    "    for col, unit in zip(dataframe.columns, units):\n",
    "        #print(col, unit)\n",
    "        unit = unit.upper()\n",
    "        if unit == \"NO-DIM\":\n",
    "            unit = \"B\"\n",
    "        if \"B\" in unit:\n",
    "            base_unit = unit.split(\"*\")[0].split(\"/\")[0]\n",
    "            factor = factors.get(base_unit, 1.0)\n",
    "            dataframe[col] *= factor\n",
    "            # Preserve suffix (*EV, /SR, etc.)\n",
    "            suffix = \"\"\n",
    "            if \"*\" in unit:\n",
    "                suffix = \"*\" + unit.split(\"*\", 1)[1]\n",
    "            elif \"/\" in unit:\n",
    "                suffix = \"/\" + unit.split(\"/\", 1)[1]\n",
    "\n",
    "            dataframe.rename(columns={col: f\"{col} (b{suffix})\"}, inplace=True)\n",
    "        else:\n",
    "            unit = (unit or \"MEV\").upper()\n",
    "            factor = factors.get(unit, 1.0)\n",
    "\n",
    "            # Scale energy data, rename column appropriately\n",
    "            dataframe[col] *= factor\n",
    "            dataframe.rename(columns={col: f\"{col} (MeV)\"}, inplace=True)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "# Fully parse block into dataframe\n",
    "def create_dataframe(data_block):\n",
    "    lines = []\n",
    "    # Clean lines, detect header/units\n",
    "    for line in data_block.strip().splitlines():\n",
    "        if line.strip():\n",
    "            lines.append(line.strip())\n",
    "    header, unit_line, start_idx = read_in_headers_and_units(lines)\n",
    "\n",
    "    # Parse data, check if the data exists\n",
    "    dataframe = parse_numeric_block(lines, start_idx)\n",
    "    if dataframe.empty:\n",
    "        return dataframe\n",
    "\n",
    "    # Check that there is actually a header\n",
    "    if header and len(header) == dataframe.shape[1]:\n",
    "        dataframe.columns = header\n",
    "    else:\n",
    "        dataframe.columns = [f\"Col{i + 1}\" for i in range(dataframe.shape[1])]\n",
    "\n",
    "    if not unit_line:\n",
    "        # Fallback to default units (MeV, b)\n",
    "        unit_line = [\"MEV\"] + [\"b\"] * (dataframe.shape[1] - 1)\n",
    "\n",
    "    # Ensure unit_line matches dataframe width\n",
    "    while len(unit_line) < len(dataframe.columns):\n",
    "        unit_line.append(\"\")\n",
    "\n",
    "    # Convert units\n",
    "    #dataframe = convert_energy_to_mev(dataframe, unit_line[0])\n",
    "    dataframe = convert_reaction_data(dataframe, unit_line)\n",
    "    return dataframe"
   ],
   "id": "6b6f06c6e36592c9",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-23T16:05:51.133651Z",
     "start_time": "2025-10-23T16:05:51.119460Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_END_CSV(filename):\n",
    "\n",
    "    # Read the CSV file\n",
    "    file_to_return = pd.read_csv(filename, sep=';', low_memory=False)\n",
    "\n",
    "    # Clean columns\n",
    "    file_to_return.columns = file_to_return.columns.str.strip()\n",
    "    file_to_return = file_to_return.dropna()\n",
    "    for column in file_to_return.columns:\n",
    "        file_to_return[column] = pd.to_numeric(file_to_return[column], errors=\"coerce\")\n",
    "\n",
    "    return file_to_return"
   ],
   "id": "2bcbf229a4f02e5c",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "12d0615f15c00bcf"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
